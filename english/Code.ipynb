{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 패키지 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 설치가 되지 않은 패키지는 anaconda에서 pip install로 설치가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "from konlpy.tag import Okt\n",
    "import networkx as nx\n",
    "from gensim.models import doc2vec\n",
    "import os\n",
    "import pyLDAvis.gensim \n",
    "import gensim.corpora as corpora\n",
    "import gensim\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import KMeans \n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.font_manager as fm\n",
    "from matplotlib import rc\n",
    "font_name = fm.FontProperties(fname=\"c:/Windows/Fonts/H2GTRE.ttf\").get_name()\n",
    "rc('font', family=font_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_extract(date):\n",
    "    return int(date[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wook\\anaconda3\\lib\\site-packages\\xlrd\\xlsx.py:266: DeprecationWarning: This method will be removed in future versions.  Use 'tree.iter()' or 'list(tree.iter())' instead.\n",
      "  for elem in self.tree.iter() if Element_has_iter else self.tree.getiterator():\n",
      "C:\\Users\\wook\\anaconda3\\lib\\site-packages\\xlrd\\xlsx.py:312: DeprecationWarning: This method will be removed in future versions.  Use 'tree.iter()' or 'list(tree.iter())' instead.\n",
      "  for elem in self.tree.iter() if Element_has_iter else self.tree.getiterator():\n",
      "C:\\Users\\wook\\anaconda3\\lib\\site-packages\\xlrd\\xlsx.py:266: DeprecationWarning: This method will be removed in future versions.  Use 'tree.iter()' or 'list(tree.iter())' instead.\n",
      "  for elem in self.tree.iter() if Element_has_iter else self.tree.getiterator():\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>product_name</th>\n",
       "      <th>score</th>\n",
       "      <th>review</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cookit</td>\n",
       "      <td>[사전예약] 스파이시 보일링랍스터&amp;쉬림프</td>\n",
       "      <td>3</td>\n",
       "      <td>기대가 너무 커서 그랬는지 제 입맛엔 그냥 ...쿡킷 메뉴 대부분 마음에 드는데 이...</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cookit</td>\n",
       "      <td>[사전예약] 리코타치즈 콜드파스타</td>\n",
       "      <td>5</td>\n",
       "      <td>아 이거 진짜 맛있네요!남편과 저는 물론이고 5살 딸도 너무너무 맛있게 잘 먹었어요...</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cookit</td>\n",
       "      <td>수삼양지수육전골</td>\n",
       "      <td>5</td>\n",
       "      <td>추천해요~국물도 따뜻하고 버섯이랑 고기 넉넉해서 한끼 잘 먹었습니다!! 맛있게 잘 ...</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cookit</td>\n",
       "      <td>평양식 어복쟁반</td>\n",
       "      <td>5</td>\n",
       "      <td>맛있게 먹고 재주문해요아이부터 어른까지 온가족 맛있게 먹었어요레시피 보고 삶은달걀인...</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cookit</td>\n",
       "      <td>감바스알아히요</td>\n",
       "      <td>5</td>\n",
       "      <td>감바스 재료를 따로 사지않고 한번에 만들어 먹을 수 있어서 좋아요 !살짝 매콤하게 ...</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company            product_name  score  \\\n",
       "0  cookit  [사전예약] 스파이시 보일링랍스터&쉬림프      3   \n",
       "1  cookit      [사전예약] 리코타치즈 콜드파스타      5   \n",
       "2  cookit                수삼양지수육전골      5   \n",
       "3  cookit                평양식 어복쟁반      5   \n",
       "4  cookit                 감바스알아히요      5   \n",
       "\n",
       "                                              review  year  \n",
       "0  기대가 너무 커서 그랬는지 제 입맛엔 그냥 ...쿡킷 메뉴 대부분 마음에 드는데 이...  2021  \n",
       "1  아 이거 진짜 맛있네요!남편과 저는 물론이고 5살 딸도 너무너무 맛있게 잘 먹었어요...  2021  \n",
       "2  추천해요~국물도 따뜻하고 버섯이랑 고기 넉넉해서 한끼 잘 먹었습니다!! 맛있게 잘 ...  2021  \n",
       "3  맛있게 먹고 재주문해요아이부터 어른까지 온가족 맛있게 먹었어요레시피 보고 삶은달걀인...  2021  \n",
       "4  감바스 재료를 따로 사지않고 한번에 만들어 먹을 수 있어서 좋아요 !살짝 매콤하게 ...  2021  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cookit = pd.read_excel('cookit.xlsx')\n",
    "cookit['year'] = cookit['date'].map(year_extract)\n",
    "cookit = cookit.iloc[:, [0,1,6,7, -1]]\n",
    "cookit.columns = ['company', 'product_name', 'score', 'review', 'year']\n",
    "cookit = cookit.loc[cookit['year'] < 2022, :]\n",
    "cookit = cookit.loc[cookit['year'] > 2018, :].reset_index(drop = True)\n",
    "cookit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wook\\anaconda3\\lib\\site-packages\\xlrd\\xlsx.py:266: DeprecationWarning: This method will be removed in future versions.  Use 'tree.iter()' or 'list(tree.iter())' instead.\n",
      "  for elem in self.tree.iter() if Element_has_iter else self.tree.getiterator():\n",
      "C:\\Users\\wook\\anaconda3\\lib\\site-packages\\xlrd\\xlsx.py:312: DeprecationWarning: This method will be removed in future versions.  Use 'tree.iter()' or 'list(tree.iter())' instead.\n",
      "  for elem in self.tree.iter() if Element_has_iter else self.tree.getiterator():\n",
      "C:\\Users\\wook\\anaconda3\\lib\\site-packages\\xlrd\\xlsx.py:266: DeprecationWarning: This method will be removed in future versions.  Use 'tree.iter()' or 'list(tree.iter())' instead.\n",
      "  for elem in self.tree.iter() if Element_has_iter else self.tree.getiterator():\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>product_name</th>\n",
       "      <th>score</th>\n",
       "      <th>review</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fresheasy</td>\n",
       "      <td>블랙라벨 스테이크 세트</td>\n",
       "      <td>5</td>\n",
       "      <td>항상 신선식품 감사합니다 블랙라벨 스테이크는 후회없이 매달 시켜먹는중이에요 ^^</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fresheasy</td>\n",
       "      <td>블랙라벨 스테이크 세트</td>\n",
       "      <td>4</td>\n",
       "      <td>가격대비 나쁘지 않았어요 괜찮았어요 두번 구매는 잘 모르겠네요 호불호가 갈릴거같아요</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fresheasy</td>\n",
       "      <td>블랙라벨 스테이크 세트</td>\n",
       "      <td>5</td>\n",
       "      <td>좋아요. 아직 먹어보진 못햇습니다. 큐커로 해벌생각하니 벌써부터 기대가 됩니다.</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fresheasy</td>\n",
       "      <td>블랙라벨 스테이크 세트</td>\n",
       "      <td>5</td>\n",
       "      <td>가격대비 고기퀄리티가 훌륭합니다!! 스테이크 치고 가격이 저렴해서 큰 기대는 하지 ...</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fresheasy</td>\n",
       "      <td>블랙라벨 스테이크 세트</td>\n",
       "      <td>5</td>\n",
       "      <td>매우만족 역시 스테디셀러는 이유가 있네요 큰 기대안했는데 너무 맛있게 먹었어요 고기...</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     company  product_name  score  \\\n",
       "0  fresheasy  블랙라벨 스테이크 세트      5   \n",
       "1  fresheasy  블랙라벨 스테이크 세트      4   \n",
       "2  fresheasy  블랙라벨 스테이크 세트      5   \n",
       "3  fresheasy  블랙라벨 스테이크 세트      5   \n",
       "4  fresheasy  블랙라벨 스테이크 세트      5   \n",
       "\n",
       "                                              review  year  \n",
       "0       항상 신선식품 감사합니다 블랙라벨 스테이크는 후회없이 매달 시켜먹는중이에요 ^^  2021  \n",
       "1     가격대비 나쁘지 않았어요 괜찮았어요 두번 구매는 잘 모르겠네요 호불호가 갈릴거같아요  2021  \n",
       "2       좋아요. 아직 먹어보진 못햇습니다. 큐커로 해벌생각하니 벌써부터 기대가 됩니다.  2021  \n",
       "3  가격대비 고기퀄리티가 훌륭합니다!! 스테이크 치고 가격이 저렴해서 큰 기대는 하지 ...  2021  \n",
       "4  매우만족 역시 스테디셀러는 이유가 있네요 큰 기대안했는데 너무 맛있게 먹었어요 고기...  2021  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fresheasy = pd.read_excel('fresheasy.xlsx')\n",
    "fresheasy['year'] = fresheasy['date'].map(year_extract)\n",
    "fresheasy = fresheasy.iloc[:, [0,1,5,6, -1]]\n",
    "fresheasy.columns = ['company', 'product_name', 'score', 'review', 'year']\n",
    "fresheasy = fresheasy.loc[fresheasy['year'] < 2022, :]\n",
    "fresheasy = fresheasy.loc[fresheasy['year'] > 2018, :].reset_index(drop = True)\n",
    "fresheasy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wook\\anaconda3\\lib\\site-packages\\xlrd\\xlsx.py:266: DeprecationWarning: This method will be removed in future versions.  Use 'tree.iter()' or 'list(tree.iter())' instead.\n",
      "  for elem in self.tree.iter() if Element_has_iter else self.tree.getiterator():\n",
      "C:\\Users\\wook\\anaconda3\\lib\\site-packages\\xlrd\\xlsx.py:312: DeprecationWarning: This method will be removed in future versions.  Use 'tree.iter()' or 'list(tree.iter())' instead.\n",
      "  for elem in self.tree.iter() if Element_has_iter else self.tree.getiterator():\n",
      "C:\\Users\\wook\\anaconda3\\lib\\site-packages\\xlrd\\xlsx.py:266: DeprecationWarning: This method will be removed in future versions.  Use 'tree.iter()' or 'list(tree.iter())' instead.\n",
      "  for elem in self.tree.iter() if Element_has_iter else self.tree.getiterator():\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>product_name</th>\n",
       "      <th>score</th>\n",
       "      <th>review</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mychef</td>\n",
       "      <td>[마이셰프X큐커] 스페니시 감바스 알아히요(2인)</td>\n",
       "      <td>4</td>\n",
       "      <td>감바스 굿! 전체적인 맛과 향은 넘 괜찮아요! 단.먹다보면 살짝 느끼한듯해서 와인하...</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mychef</td>\n",
       "      <td>[마이셰프X큐커] 스페니시 감바스 알아히요(2인)</td>\n",
       "      <td>5</td>\n",
       "      <td>맛있어요. 추천합니다. 달콤 짭쪼름하니 맛있네요. 가격은 좀 비싼편이지만 한끼 식사...</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mychef</td>\n",
       "      <td>[마이셰프X큐커] 스페니시 감바스 알아히요(2인)</td>\n",
       "      <td>4</td>\n",
       "      <td>맛나요 재구매입니다 조리가 편한데 이것도 큐커 바코드 인식이 안되네요ㅠㅠ 그럼 몇도...</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mychef</td>\n",
       "      <td>[마이셰프X큐커] 스페니시 감바스 알아히요(2인)</td>\n",
       "      <td>5</td>\n",
       "      <td>너무 맛있게 먹었어요! 큐커 들이고나서 마이쉐프에서 주문해서 먹었는데사용법도 너무 ...</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mychef</td>\n",
       "      <td>[마이셰프X큐커] 스페니시 감바스 알아히요(2인)</td>\n",
       "      <td>4</td>\n",
       "      <td>간편해요~ 큐커 밀키트 중 젤 간편하네요  첨부파일  20210925_191729.jpg</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company                 product_name  score  \\\n",
       "0  mychef  [마이셰프X큐커] 스페니시 감바스 알아히요(2인)      4   \n",
       "1  mychef  [마이셰프X큐커] 스페니시 감바스 알아히요(2인)      5   \n",
       "2  mychef  [마이셰프X큐커] 스페니시 감바스 알아히요(2인)      4   \n",
       "3  mychef  [마이셰프X큐커] 스페니시 감바스 알아히요(2인)      5   \n",
       "4  mychef  [마이셰프X큐커] 스페니시 감바스 알아히요(2인)      4   \n",
       "\n",
       "                                              review  year  \n",
       "0  감바스 굿! 전체적인 맛과 향은 넘 괜찮아요! 단.먹다보면 살짝 느끼한듯해서 와인하...  2021  \n",
       "1  맛있어요. 추천합니다. 달콤 짭쪼름하니 맛있네요. 가격은 좀 비싼편이지만 한끼 식사...  2021  \n",
       "2  맛나요 재구매입니다 조리가 편한데 이것도 큐커 바코드 인식이 안되네요ㅠㅠ 그럼 몇도...  2021  \n",
       "3  너무 맛있게 먹었어요! 큐커 들이고나서 마이쉐프에서 주문해서 먹었는데사용법도 너무 ...  2021  \n",
       "4  간편해요~ 큐커 밀키트 중 젤 간편하네요  첨부파일  20210925_191729.jpg  2021  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mychef = pd.read_excel('mychef.xlsx')\n",
    "mychef['year'] = mychef['date'].map(year_extract)\n",
    "mychef = mychef.iloc[:, [0,1,4,7,-1]]\n",
    "mychef.columns = ['company', 'product_name', 'score', 'review', 'year']\n",
    "mychef = mychef.loc[mychef['year'] < 2022, :]\n",
    "mychef = mychef.loc[mychef['year'] > 2018, :].reset_index(drop = True)\n",
    "mychef.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wook\\anaconda3\\lib\\site-packages\\xlrd\\xlsx.py:266: DeprecationWarning: This method will be removed in future versions.  Use 'tree.iter()' or 'list(tree.iter())' instead.\n",
      "  for elem in self.tree.iter() if Element_has_iter else self.tree.getiterator():\n",
      "C:\\Users\\wook\\anaconda3\\lib\\site-packages\\xlrd\\xlsx.py:312: DeprecationWarning: This method will be removed in future versions.  Use 'tree.iter()' or 'list(tree.iter())' instead.\n",
      "  for elem in self.tree.iter() if Element_has_iter else self.tree.getiterator():\n",
      "C:\\Users\\wook\\anaconda3\\lib\\site-packages\\xlrd\\xlsx.py:266: DeprecationWarning: This method will be removed in future versions.  Use 'tree.iter()' or 'list(tree.iter())' instead.\n",
      "  for elem in self.tree.iter() if Element_has_iter else self.tree.getiterator():\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>product_name</th>\n",
       "      <th>score</th>\n",
       "      <th>review</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fredit</td>\n",
       "      <td>차돌박이 순두부찌개</td>\n",
       "      <td>5.0</td>\n",
       "      <td>맛있어요~</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fredit</td>\n",
       "      <td>차돌박이 순두부찌개</td>\n",
       "      <td>5.0</td>\n",
       "      <td>순두부가 부드러워 좋네요</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fredit</td>\n",
       "      <td>차돌박이 순두부찌개</td>\n",
       "      <td>5.0</td>\n",
       "      <td>맛있게 잘 먹었어요</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fredit</td>\n",
       "      <td>차돌박이 순두부찌개</td>\n",
       "      <td>5.0</td>\n",
       "      <td>좋아요</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fredit</td>\n",
       "      <td>차돌박이 순두부찌개</td>\n",
       "      <td>5.0</td>\n",
       "      <td>맛나요</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company product_name  score          review  year\n",
       "0  fredit   차돌박이 순두부찌개    5.0           맛있어요~  2021\n",
       "1  fredit   차돌박이 순두부찌개    5.0  순두부가 부드러워 좋네요   2021\n",
       "2  fredit   차돌박이 순두부찌개    5.0      맛있게 잘 먹었어요  2021\n",
       "3  fredit   차돌박이 순두부찌개    5.0             좋아요  2021\n",
       "4  fredit   차돌박이 순두부찌개    5.0             맛나요  2021"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itson = pd.read_excel('잇츠온.xlsx')\n",
    "itson['year'] = itson['date'].map(year_extract)\n",
    "itson = itson.iloc[:, [0,1,7,8,-1]]\n",
    "itson.columns = ['company', 'product_name', 'score', 'review', 'year']\n",
    "itson = itson.loc[itson['year'] < 2022, :]\n",
    "itson = itson.loc[itson['year'] > 2018, :].reset_index(drop = True)\n",
    "itson.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>product_name</th>\n",
       "      <th>score</th>\n",
       "      <th>review</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cookit</td>\n",
       "      <td>[사전예약] 스파이시 보일링랍스터&amp;쉬림프</td>\n",
       "      <td>3.0</td>\n",
       "      <td>기대가 너무 커서 그랬는지 제 입맛엔 그냥 ...쿡킷 메뉴 대부분 마음에 드는데 이...</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cookit</td>\n",
       "      <td>[사전예약] 리코타치즈 콜드파스타</td>\n",
       "      <td>5.0</td>\n",
       "      <td>아 이거 진짜 맛있네요!남편과 저는 물론이고 5살 딸도 너무너무 맛있게 잘 먹었어요...</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cookit</td>\n",
       "      <td>수삼양지수육전골</td>\n",
       "      <td>5.0</td>\n",
       "      <td>추천해요~국물도 따뜻하고 버섯이랑 고기 넉넉해서 한끼 잘 먹었습니다!! 맛있게 잘 ...</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cookit</td>\n",
       "      <td>평양식 어복쟁반</td>\n",
       "      <td>5.0</td>\n",
       "      <td>맛있게 먹고 재주문해요아이부터 어른까지 온가족 맛있게 먹었어요레시피 보고 삶은달걀인...</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cookit</td>\n",
       "      <td>감바스알아히요</td>\n",
       "      <td>5.0</td>\n",
       "      <td>감바스 재료를 따로 사지않고 한번에 만들어 먹을 수 있어서 좋아요 !살짝 매콤하게 ...</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company            product_name  score  \\\n",
       "0  cookit  [사전예약] 스파이시 보일링랍스터&쉬림프    3.0   \n",
       "1  cookit      [사전예약] 리코타치즈 콜드파스타    5.0   \n",
       "2  cookit                수삼양지수육전골    5.0   \n",
       "3  cookit                평양식 어복쟁반    5.0   \n",
       "4  cookit                 감바스알아히요    5.0   \n",
       "\n",
       "                                              review  year  \n",
       "0  기대가 너무 커서 그랬는지 제 입맛엔 그냥 ...쿡킷 메뉴 대부분 마음에 드는데 이...  2021  \n",
       "1  아 이거 진짜 맛있네요!남편과 저는 물론이고 5살 딸도 너무너무 맛있게 잘 먹었어요...  2021  \n",
       "2  추천해요~국물도 따뜻하고 버섯이랑 고기 넉넉해서 한끼 잘 먹었습니다!! 맛있게 잘 ...  2021  \n",
       "3  맛있게 먹고 재주문해요아이부터 어른까지 온가족 맛있게 먹었어요레시피 보고 삶은달걀인...  2021  \n",
       "4  감바스 재료를 따로 사지않고 한번에 만들어 먹을 수 있어서 좋아요 !살짝 매콤하게 ...  2021  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([cookit, fresheasy, mychef, itson]).reset_index(drop = True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 공란 데이터 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset = ['product_name']).reset_index(drop = True)\n",
    "data = data.dropna(subset = ['review']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### review가 두글자 이상인 경우만 남기기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = []\n",
    "for i in range(len(data['review'])):\n",
    "    if len(data['review'][i]) > 1:\n",
    "        sample.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.iloc[sample, :].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10개 이상의 리뷰가 있는 제품만 남기기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_count = pd.DataFrame.from_dict( Counter(data['product_name']), orient='index').reset_index()\n",
    "product_count = product_count.loc[product_count[0] > 9, :]\n",
    "product_list = list(product_count['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[data['product_name'].isin(product_list), :].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211535"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['product_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Textmining을 하기위해서는 List형태로 단어들은 Tokenize 해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) 합성어 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동의어 처리\n",
    "Comb_words = [['에어프라이기'], ['프레시지'], ['배불리'], ['비쥬얼'], ['구매평'], ['밀키트'], ['유린기'], ['질리다'], ['마이셰프', '마이쉐프'], ['프라이팬'], ['쿠킷', '쿳킷'], ['유통기한'], ['알리오올리오'], ['비리다'], ['파스타'], ['푸팟퐁커리'], ['먹어보지'], ['취향저격'], ['우육면'], ['제입'], ['전체적'], ['건고추'], ['강추'], ['초무침'], ['구성품'], ['정기배송'], ['감바스'], ['가성비'], ['엄지척'], ['구매평'], ['푸짐'], ['쉬림프'], ['CJ', 'cj'], ['새콤달콤'], ['플레이팅']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TRSF', 'TRSFTRSF', 'TRSFTRSFTRSF']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Transform_words = ['TRSF' * (i+1) for i in range(len(Comb_words))]\n",
    "Transform_words[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Word_transform(Text, word_list, to_word):\n",
    "    for word in word_list:\n",
    "        Text = str(Text).replace(word,to_word)\n",
    "    return Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Comb_words)):\n",
    "    data['review'] = [Word_transform(abstract, Comb_words[i], Transform_words[i]) for abstract in data['review']]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 명사\n",
    "#tags = ['Noun', 'Alpha']\n",
    "\n",
    "# 명사, 형용사\n",
    "tags = ['Noun']\n",
    "# 불용어 처리\n",
    "stopwords = ['입니다','완전','전부','같아요','대한', '있어서', '있는', '약간', '있어요', '살짝', '적당히', '그냥', '있어', '역시', '모두', '있습니다', '다만', '보고', '같은', '있고', '편이', '같습니다', '좀더', 'jpg', '첨부파일', '때문', '일단', '리뷰', '이서', '그런지', '이상', '가장', '바로', '이건', '사서', '충분히', '안나', '없는', '같네요', '없어서', '있네요', '있었어요', '기도', '없고', '있는데', '거의', '무엇', '하니', '있으면', '없네요', '없어요', '전혀', '추합니다', '이런', '같아서', '아니라', '워낙', '같아', '여기', '뭔가', '해도', '있을', '있던', '비주', '위해', '우선', '불리', '있으니', '있지만', '대로', '사실', '같은데', 'jpeg', '없을', '있었습니다', '있게', '있었으면', '기지', '있음',' 같고', '자꾸', '있다니', '없어', '그런', '그것', '짐해', '수도', '미가', '다가', '인지', '있었는데', '듭니', '만해', '없습니다', '이기', '없었어요', '그닥', '그게', '내기', '편입', '런가', '끼리', '기고', '혹시', '그랬어요', '그거', '질도', '서도', '있었지만', '처럼', '이예', '문해', '고요', '이면', '이나', '알도', '그럴', '이구', '한수', '입니당', '그렇고', '거리', '있었네요', '만하', '가요', '있구요', '어요', '있는거', '주시', '수가', '없는데', '나니', '번은', '는걸', '요건', '어떤', '야해요', '있을걸', '단지', '아예', '성하게', '있다면', '있다는', '고해', '드네', '양장', '없었는데', '로만', '있었음', '있다', '리오', '시기', '어도', '비도', '점점', '없지만', '보이', '차라리', '하라', '그래요', '그렇지', '같기도', '거나', '등등', '더더']\n",
    "\n",
    "\n",
    "def Tokenizer(text):\n",
    "    morphs = Okt.pos(text)\n",
    "    if len(morphs) > 0:\n",
    "        pos = []\n",
    "\n",
    "        for x in morphs:\n",
    "            if len(x) > 1:\n",
    "                word, tag = x\n",
    "                if(word in stopwords): \n",
    "                    continue\n",
    "                if tag in tags:\n",
    "                    pos.append(word)\n",
    "    else:\n",
    "        pos = ['nan']\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['기대', '커서', '제', '입맛', '쿡킷', '메뉴', '대부분', '마음', '테', '맛'],\n",
       " ['거',\n",
       "  '진짜',\n",
       "  '남편',\n",
       "  '저',\n",
       "  '살',\n",
       "  '딸도',\n",
       "  '상큼',\n",
       "  '함',\n",
       "  '말',\n",
       "  '식감',\n",
       "  '푸른',\n",
       "  '채소',\n",
       "  '리코',\n",
       "  '신의',\n",
       "  '리코',\n",
       "  '치즈',\n",
       "  '리코',\n",
       "  '치즈',\n",
       "  '통',\n",
       "  '뭐',\n",
       "  '젓가락',\n",
       "  '질',\n",
       "  '때',\n",
       "  '계속',\n",
       "  '크리스마스',\n",
       "  '외식',\n",
       "  '마음',\n",
       "  '걸',\n",
       "  '방'],\n",
       " ['추천', '국물', '버섯', '고기', '끼']]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Token = [Tokenizer(text) for text in data['review']]\n",
    "Token[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) 앞서 바꿔준 합성어를 다시 원상태로 복구합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Word_restore(Text, word1, word2):\n",
    "    transformed_list = []\n",
    "    for word in Text:\n",
    "        if word1 in word:\n",
    "            word = word2\n",
    "        transformed_list.append(word)\n",
    "    return transformed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['기대', '커서', '제', '입맛', '쿡킷', '메뉴', '대부분', '마음', '테', '맛'],\n",
       " ['거',\n",
       "  '진짜',\n",
       "  '남편',\n",
       "  '저',\n",
       "  '살',\n",
       "  '딸도',\n",
       "  '상큼',\n",
       "  '함',\n",
       "  '말',\n",
       "  '식감',\n",
       "  '푸른',\n",
       "  '채소',\n",
       "  '리코',\n",
       "  '신의',\n",
       "  '리코',\n",
       "  '치즈',\n",
       "  '리코',\n",
       "  '치즈',\n",
       "  '통',\n",
       "  '뭐',\n",
       "  '젓가락',\n",
       "  '질',\n",
       "  '때',\n",
       "  '계속',\n",
       "  '크리스마스',\n",
       "  '외식',\n",
       "  '마음',\n",
       "  '걸',\n",
       "  '방'],\n",
       " ['추천', '국물', '버섯', '고기', '끼']]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Comb_words = [word_list[0] for word_list in Comb_words]\n",
    "for i in range(1, len(Comb_words) + 1):\n",
    "    Token = [Word_restore(token, Transform_words[-i], Comb_words[-i]) for token in Token] \n",
    "Token[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) 한 글자 단어들도 제거해줄 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_char_remove(Token):\n",
    "    \n",
    "    Token = [word for word in Token if (len(word) > 1 or word == '맛')]\n",
    "    return Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_char_remove(Token):\n",
    "    Token = [word for word in Token if len(word) > 1]\n",
    "    return Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_char_remove(Token):\n",
    "    Token = [word for word in Token if word in list(word_count['Word'])]\n",
    "    return Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'맛' in list(word_count['Word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['기대', '커서', '입맛', '쿡킷', '메뉴', '대부분', '마음', '맛'],\n",
       " ['진짜',\n",
       "  '남편',\n",
       "  '딸도',\n",
       "  '상큼',\n",
       "  '식감',\n",
       "  '채소',\n",
       "  '신의',\n",
       "  '치즈',\n",
       "  '치즈',\n",
       "  '젓가락',\n",
       "  '계속',\n",
       "  '크리스마스',\n",
       "  '외식',\n",
       "  '마음'],\n",
       " ['추천', '국물', '버섯', '고기'],\n",
       " ['재주', '아이', '어른', '가족', '레시피', '달걀'],\n",
       " ['재료', '사지', '한번', '매콤'],\n",
       " ['아이', '크리스마스', '분위기', '요리', '가족'],\n",
       " ['재료', '겨울', '맛', '해산물', '하나', '재미', '매콤', '콩나물', '그릇', '금방', '뚝딱'],\n",
       " ['양은', '조절', '추가', '사용', '수비드', '치킨', '추천'],\n",
       " ['만들기', '맛', '혼자', '오븐', '진짜', '개발', '한번', '구매'],\n",
       " ['고생', '부모님', '생각', '친정', '전화'],\n",
       " ['재료', '만들기', '피자', '맛'],\n",
       " ['부채살', '스테이크', '기름', '고기'],\n",
       " ['쿡킷', '맛', '요리', '수비드', '사태', '갈비찜'],\n",
       " ['음식', '메뉴', '아주', '재료'],\n",
       " ['피자', '치즈', '또띠아', '남아', '피자', '치즈', '듬뿍'],\n",
       " ['고기', '기름', '기름', '고기', '이적', '야채'],\n",
       " ['다음', '의사', '나중'],\n",
       " ['레시피', '따라서', '가족', '식사'],\n",
       " ['고등학생', '아이', '레시피', '요리', '고등어', '조합'],\n",
       " ['레시피', '따라서', '가족', '식사']]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Token = [one_char_remove(token) for token in Token]\n",
    "Token[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_tokens = list(itertools.chain(*Token))\n",
    "token_count = Counter(flatten_tokens)\n",
    "Top_token_count = token_count.most_common(2000)\n",
    "    \n",
    "word_count = pd.DataFrame(Top_token_count)\n",
    "word_count.columns = ['Word', 'Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>맛</td>\n",
       "      <td>83440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>고기</td>\n",
       "      <td>29602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>주문</td>\n",
       "      <td>28082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>조리</td>\n",
       "      <td>27806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>요리</td>\n",
       "      <td>26828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>앞뒤</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>낼때</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>매뉴얼</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>사전예약</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>쫄깃함</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Word  Count\n",
       "0        맛  83440\n",
       "1       고기  29602\n",
       "2       주문  28082\n",
       "3       조리  27806\n",
       "4       요리  26828\n",
       "...    ...    ...\n",
       "1995    앞뒤     48\n",
       "1996    낼때     48\n",
       "1997   매뉴얼     48\n",
       "1998  사전예약     48\n",
       "1999   쫄깃함     48\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visulize(noun_list, filename, white = True):\n",
    "    if white == True:\n",
    "        wordcloud = WordCloud(width=2000, height=1000, font_path = 'C:/Windows/Fonts/malgun.ttf', collocations=True, background_color='white')\n",
    "    else:\n",
    "        wordcloud = WordCloud(width=2000, height=1000, font_path = 'C:/Windows/Fonts/malgun.ttf', collocations=True)\n",
    "    wordcloud.generate_from_frequencies(dict(noun_list))\n",
    "    wordcloud.to_file(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordcloud_Rank(token, N = 30, white = True):\n",
    "    if not os.path.exists('./Wordcloud'):\n",
    "        os.makedirs('./Wordcloud')\n",
    "    filename = 'Wordcloud/keyword_wordcloud.png'\n",
    "    filename_csv = 'Wordcloud/keyword_count.csv'\n",
    "    \n",
    "    flatten_tokens = list(itertools.chain(*token))\n",
    "    token_count = Counter(flatten_tokens)\n",
    "    Top_token_count = token_count.most_common(N)\n",
    "    \n",
    "    word_count = pd.DataFrame(Top_token_count)\n",
    "    word_count.columns = ['Word', 'Count']\n",
    "    word_count.to_csv(filename_csv, index = False, encoding='euc-kr')\n",
    "    \n",
    "    visulize(Top_token_count, filename, white)\n",
    "    return word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = wordcloud_Rank(Token, 50, white = False)\n",
    "word_count.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-52-f33233f7e71e>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Precessed_text'][ind] = ' '.join(Token[ind])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>product_name</th>\n",
       "      <th>score</th>\n",
       "      <th>review</th>\n",
       "      <th>year</th>\n",
       "      <th>Precessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cookit</td>\n",
       "      <td>[사전예약] 스파이시 보일링랍스터&amp;쉬림프</td>\n",
       "      <td>3.0</td>\n",
       "      <td>기대가 너무 커서 그랬는지 제 입맛엔 그냥 ...쿡킷 메뉴 대부분 마음에 드는데 이...</td>\n",
       "      <td>2021</td>\n",
       "      <td>기대 커서 입맛 쿡킷 메뉴 대부분 마음 맛</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cookit</td>\n",
       "      <td>[사전예약] 리코타치즈 콜드파스타</td>\n",
       "      <td>5.0</td>\n",
       "      <td>아 이거 진짜 맛있네요!남편과 저는 물론이고 5살 딸도 너무너무 맛있게 잘 먹었어요...</td>\n",
       "      <td>2021</td>\n",
       "      <td>진짜 남편 딸도 상큼 식감 채소 신의 치즈 치즈 젓가락 계속 크리스마스 외식 마음</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cookit</td>\n",
       "      <td>수삼양지수육전골</td>\n",
       "      <td>5.0</td>\n",
       "      <td>추천해요~국물도 따뜻하고 버섯이랑 고기 넉넉해서 한끼 잘 먹었습니다!! 맛있게 잘 ...</td>\n",
       "      <td>2021</td>\n",
       "      <td>추천 국물 버섯 고기</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cookit</td>\n",
       "      <td>평양식 어복쟁반</td>\n",
       "      <td>5.0</td>\n",
       "      <td>맛있게 먹고 재주문해요아이부터 어른까지 온가족 맛있게 먹었어요레시피 보고 삶은달걀인...</td>\n",
       "      <td>2021</td>\n",
       "      <td>재주 아이 어른 가족 레시피 달걀</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cookit</td>\n",
       "      <td>감바스알아히요</td>\n",
       "      <td>5.0</td>\n",
       "      <td>TRSFTRSFTRSFTRSFTRSFTRSFTRSFTRSFTRSFTRSFTRSFTR...</td>\n",
       "      <td>2021</td>\n",
       "      <td>재료 사지 한번 매콤</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company            product_name  score  \\\n",
       "0  cookit  [사전예약] 스파이시 보일링랍스터&쉬림프    3.0   \n",
       "1  cookit      [사전예약] 리코타치즈 콜드파스타    5.0   \n",
       "2  cookit                수삼양지수육전골    5.0   \n",
       "3  cookit                평양식 어복쟁반    5.0   \n",
       "4  cookit                 감바스알아히요    5.0   \n",
       "\n",
       "                                              review  year  \\\n",
       "0  기대가 너무 커서 그랬는지 제 입맛엔 그냥 ...쿡킷 메뉴 대부분 마음에 드는데 이...  2021   \n",
       "1  아 이거 진짜 맛있네요!남편과 저는 물론이고 5살 딸도 너무너무 맛있게 잘 먹었어요...  2021   \n",
       "2  추천해요~국물도 따뜻하고 버섯이랑 고기 넉넉해서 한끼 잘 먹었습니다!! 맛있게 잘 ...  2021   \n",
       "3  맛있게 먹고 재주문해요아이부터 어른까지 온가족 맛있게 먹었어요레시피 보고 삶은달걀인...  2021   \n",
       "4  TRSFTRSFTRSFTRSFTRSFTRSFTRSFTRSFTRSFTRSFTRSFTR...  2021   \n",
       "\n",
       "                                  Precessed_text  \n",
       "0                        기대 커서 입맛 쿡킷 메뉴 대부분 마음 맛  \n",
       "1  진짜 남편 딸도 상큼 식감 채소 신의 치즈 치즈 젓가락 계속 크리스마스 외식 마음  \n",
       "2                                    추천 국물 버섯 고기  \n",
       "3                             재주 아이 어른 가족 레시피 달걀  \n",
       "4                                    재료 사지 한번 매콤  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Precessed_text'] = ''\n",
    "for ind in range(len(Token)):\n",
    "    data['Precessed_text'][ind] = ' '.join(Token[ind])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:, ['company', 'Precessed_text']].to_csv('tf-idf_data.csv', index = False, encoding = 'euc-kr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211535"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_num = len(data['Precessed_text'])\n",
    "doc_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "tdm = cv.fit_transform(data['Precessed_text'])\n",
    "tdm = tdm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "words = cv.get_feature_names()\n",
    "word_count = tdm.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdm[tdm > 1] = 1\n",
    "word_doc = tdm.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = word_count / doc_num\n",
    "idf = np.log(doc_num / word_doc)\n",
    "tf_idf = tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>고기</td>\n",
       "      <td>0.297999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1558</th>\n",
       "      <td>주문</td>\n",
       "      <td>0.285046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>요리</td>\n",
       "      <td>0.282026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>조리</td>\n",
       "      <td>0.279169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>소스</td>\n",
       "      <td>0.273179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>재료</td>\n",
       "      <td>0.270027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>아이</td>\n",
       "      <td>0.254161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>메뉴</td>\n",
       "      <td>0.243109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>양도</td>\n",
       "      <td>0.230313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506</th>\n",
       "      <td>정말</td>\n",
       "      <td>0.218824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>야채</td>\n",
       "      <td>0.216231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>조금</td>\n",
       "      <td>0.214571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>국물</td>\n",
       "      <td>0.212832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>먹기</td>\n",
       "      <td>0.210491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>추가</td>\n",
       "      <td>0.204762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>생각</td>\n",
       "      <td>0.201045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752</th>\n",
       "      <td>쿡킷</td>\n",
       "      <td>0.187553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>아주</td>\n",
       "      <td>0.184770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>구매</td>\n",
       "      <td>0.181244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>새우</td>\n",
       "      <td>0.170997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>양념</td>\n",
       "      <td>0.167312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>가족</td>\n",
       "      <td>0.152284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>음식</td>\n",
       "      <td>0.144630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609</th>\n",
       "      <td>진짜</td>\n",
       "      <td>0.141385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>인분</td>\n",
       "      <td>0.137266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>정도</td>\n",
       "      <td>0.136260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>처음</td>\n",
       "      <td>0.135035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>매콤</td>\n",
       "      <td>0.133727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>자주</td>\n",
       "      <td>0.124411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>배송</td>\n",
       "      <td>0.123579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Word     Score\n",
       "114    고기  0.297999\n",
       "1558   주문  0.285046\n",
       "1285   요리  0.282026\n",
       "1530   조리  0.279169\n",
       "949    소스  0.273179\n",
       "1452   재료  0.270027\n",
       "1108   아이  0.254161\n",
       "586    메뉴  0.243109\n",
       "1143   양도  0.230313\n",
       "1506   정말  0.218824\n",
       "1137   야채  0.216231\n",
       "1528   조금  0.214571\n",
       "159    국물  0.212832\n",
       "577    먹기  0.210491\n",
       "1702   추가  0.204762\n",
       "893    생각  0.201045\n",
       "1752   쿡킷  0.187553\n",
       "1112   아주  0.184770\n",
       "147    구매  0.181244\n",
       "887    새우  0.170997\n",
       "1141   양념  0.167312\n",
       "28     가족  0.152284\n",
       "1339   음식  0.144630\n",
       "1609   진짜  0.141385\n",
       "1386   인분  0.137266\n",
       "1503   정도  0.136260\n",
       "1672   처음  0.135035\n",
       "568    매콤  0.133727\n",
       "1428   자주  0.124411\n",
       "707    배송  0.123579"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TF_IDF = pd.DataFrame({'Word': words, 'Score': tf_idf})\n",
    "TF_IDF = TF_IDF.sort_values(by=['Score'], axis=0, ascending=False)\n",
    "TF_IDF.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_IDF = TF_IDF.reset_index(drop = True)\n",
    "TF_IDF.to_csv('TF_IDF.csv', index = False, encoding='euc-kr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) LDA에 필요한 환경설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word=corpora.Dictionary(Token)\n",
    "id2word.filter_extremes(no_below = 3) #3회 이하로 등장한 단어는 삭제\n",
    "texts = Token\n",
    "corpus=[id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) LDA는 토픽 수를 정해주어야 하며, 이 때, Coherence 값이 높은 K로 정하는게 일반적입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=4, step=2):\n",
    "\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = gensim.models.coherencemodel.CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "    \n",
    "    x = range(start, limit, step) \n",
    "    plt.plot(x, coherence_values) \n",
    "    plt.xlabel(\"Num Topics\") \n",
    "    plt.ylabel(\"Coherence score\") \n",
    "    plt.legend((\"coherence_values\"), loc='best') \n",
    "    plt.show()\n",
    "    \n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 그래프에서 y축이 가장 높은 K가 최적의 토픽 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=texts, start=3, limit=11, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) 최적의 토픽 개수를 찾아, 이에 맞게 토픽모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 6\n",
    "num_words = 30\n",
    "# model = LdaModel(corpus=corpus, num_topics=K, id2word=id2word)\n",
    "topics = model_list[2].print_topics(num_words=num_words) \n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 6\n",
    "num_words = 30\n",
    "model1 = LdaModel(corpus=corpus, num_topics=K, id2word=id2word)\n",
    "topics = model1.print_topics(num_words=num_words) \n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 6\n",
    "num_words = 30\n",
    "model2 = LdaModel(corpus=corpus, num_topics=K, id2word=id2word)\n",
    "topics = model2.print_topics(num_words=num_words) \n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 6\n",
    "num_words = 30\n",
    "model3 = LdaModel(corpus=corpus, num_topics=K, id2word=id2word)\n",
    "topics = model3.print_topics(num_words=num_words) \n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 6\n",
    "num_words = 30\n",
    "model4 = LdaModel(corpus=corpus, num_topics=K, id2word=id2word)\n",
    "topics = model4.print_topics(num_words=num_words) \n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 6\n",
    "num_words = 30\n",
    "model5 = LdaModel(corpus=corpus, num_topics=K, id2word=id2word)\n",
    "topics = model5.print_topics(num_words=num_words) \n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 6\n",
    "num_words = 30\n",
    "model6 = LdaModel(corpus=corpus, num_topics=K, id2word=id2word)\n",
    "topics = model6.print_topics(num_words=num_words) \n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 6\n",
    "num_words = 30\n",
    "model7 = LdaModel(corpus=corpus, num_topics=K, id2word=id2word)\n",
    "topics = model7.print_topics(num_words=num_words) \n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 6\n",
    "num_words = 30\n",
    "model8 = LdaModel(corpus=corpus, num_topics=K, id2word=id2word)\n",
    "topics = model8.print_topics(num_words=num_words) \n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 6\n",
    "num_words = 30\n",
    "model9 = LdaModel(corpus=corpus, num_topics=K, id2word=id2word)\n",
    "topics = model9.print_topics(num_words=num_words) \n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = np.zeros((len(model[corpus]), 6))\n",
    "for doc in range(len(model[corpus])):\n",
    "    for topic, proba in model[corpus][doc]:\n",
    "        prob[doc, topic] = proba\n",
    "        \n",
    "prob = pd.DataFrame(prob)\n",
    "prob.columns = ['Topic1', 'Topic2', 'Topic3', 'Topic4', 'Topic5', 'Topic6']\n",
    "prob.to_csv('topic_porb.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(model_list[2], corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(Token)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents, vector_size=128, window=5, epochs=100, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Similar_words(Doc2vec_model, Keyword, N):\n",
    "    Similar_keywords = Doc2vec_model.wv.most_similar(Keyword, topn = N)\n",
    "    Keywords = [word for (word, similarity) in Similar_keywords]\n",
    "    Rank = list(range(1, N + 1))\n",
    "    Result = pd.DataFrame({'Rank' : Rank, 'Keyword' : Keywords})\n",
    "    return Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = '배송'\n",
    "Similar_words_list = Similar_words(model, keyword, 100)\n",
    "Similar_words_list.to_csv(keyword + '관련단어.csv', index = False, encoding = 'euc-kr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = '가격'\n",
    "Similar_words_list = Similar_words(model, keyword, 100)\n",
    "Similar_words_list.to_csv(keyword + '관련단어.csv', index = False, encoding = 'euc-kr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = '재료'\n",
    "Similar_words_list = Similar_words(model, keyword, 100)\n",
    "Similar_words_list.to_csv(keyword + '관련단어.csv', index = False, encoding = 'euc-kr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = '시간'\n",
    "Similar_words_list = Similar_words(model, keyword, 100)\n",
    "Similar_words_list.to_csv(keyword + '관련단어.csv', index = False, encoding = 'euc-kr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = '맛'\n",
    "Similar_words_list = Similar_words(model, keyword, 100)\n",
    "Similar_words_list.to_csv(keyword + '관련단어.csv', index = False, encoding = 'euc-kr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doc2vec 결과를 Dataframe으로 저장해봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Word 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_words = []\n",
    "for idx, key in enumerate(model.wv.vocab):\n",
    "    my_words = my_words + [key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wordvec_result = pd.DataFrame({'Keyword': my_words})\n",
    "Wordvec_result = pd.concat([Wordvec_result,pd.DataFrame(model[my_words])], axis=1)\n",
    "Wordvec_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wordvec_result.to_csv('doc2vec_result_word.csv', index = False, encoding='euc-kr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Document 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vec_array = model.docvecs[0]\n",
    "for i in range(1, len(documents)):\n",
    "    doc_vec_array = np.vstack([doc_vec_array, model.docvecs[i]])\n",
    "doc_vec_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vec_df = pd.DataFrame(doc_vec_array)\n",
    "doc_vec_df.to_csv('doc2vec_result_doc.csv', index = False, encoding='euc-kr')\n",
    "doc_vec_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Randomforest 적합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor()\n",
    "model.fit(doc_vec_array, data['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.predict(Wordvec_result.iloc[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_score = pd.DataFrame({'Keyword': Wordvec_result['Keyword'], 'Score' : score})\n",
    "sentiment_score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_score.to_csv('sentiment_score.csv', index = False, encoding = 'euc-kr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_score = pd.read_csv('sentiment_score.csv', encoding = 'euc-kr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_score['Score'] = 1 +  (max(sentiment_score['Score']) - sentiment_score['Score']) / (max(sentiment_score['Score']) - min(sentiment_score['Score'])) * 4\n",
    "import math\n",
    "sentiment_score['Score'] = sentiment_score['Score'].map(round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(sentiment_score['Score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 토픽 감성 점수 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_porb = pd.read_csv('topic_porb_mk.csv', encoding = 'euc-kr')\n",
    "topic_porb['Score'] = data['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic1</th>\n",
       "      <th>Topic2</th>\n",
       "      <th>Topic3</th>\n",
       "      <th>Topic4</th>\n",
       "      <th>Topic5</th>\n",
       "      <th>Topic6</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016954</td>\n",
       "      <td>0.175372</td>\n",
       "      <td>0.016795</td>\n",
       "      <td>0.393785</td>\n",
       "      <td>0.269118</td>\n",
       "      <td>0.127975</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.431590</td>\n",
       "      <td>0.328817</td>\n",
       "      <td>0.097755</td>\n",
       "      <td>0.088636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046433</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.020890</td>\n",
       "      <td>0.021022</td>\n",
       "      <td>0.707705</td>\n",
       "      <td>0.021015</td>\n",
       "      <td>0.208400</td>\n",
       "      <td>0.020968</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.018545</td>\n",
       "      <td>0.626032</td>\n",
       "      <td>0.018925</td>\n",
       "      <td>0.018650</td>\n",
       "      <td>0.018624</td>\n",
       "      <td>0.299224</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.024013</td>\n",
       "      <td>0.562663</td>\n",
       "      <td>0.024059</td>\n",
       "      <td>0.024084</td>\n",
       "      <td>0.023932</td>\n",
       "      <td>0.341248</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic1    Topic2    Topic3    Topic4    Topic5    Topic6  Score\n",
       "0  0.016954  0.175372  0.016795  0.393785  0.269118  0.127975    3.0\n",
       "1  0.431590  0.328817  0.097755  0.088636  0.000000  0.046433    5.0\n",
       "2  0.020890  0.021022  0.707705  0.021015  0.208400  0.020968    5.0\n",
       "3  0.018545  0.626032  0.018925  0.018650  0.018624  0.299224    5.0\n",
       "4  0.024013  0.562663  0.024059  0.024084  0.023932  0.341248    5.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_porb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Score</td>      <th>  R-squared:         </th>  <td>   0.060</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.060</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   2265.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 23 May 2022</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:29:10</td>     <th>  Log-Likelihood:    </th> <td>-2.0523e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>211535</td>      <th>  AIC:               </th>  <td>4.105e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>211528</td>      <th>  BIC:               </th>  <td>4.106e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    3.3455</td> <td>    0.263</td> <td>   12.744</td> <td> 0.000</td> <td>    2.831</td> <td>    3.860</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Topic1</th>    <td>    1.0739</td> <td>    0.263</td> <td>    4.081</td> <td> 0.000</td> <td>    0.558</td> <td>    1.590</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Topic2</th>    <td>    1.5554</td> <td>    0.263</td> <td>    5.917</td> <td> 0.000</td> <td>    1.040</td> <td>    2.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Topic3</th>    <td>    1.6377</td> <td>    0.263</td> <td>    6.232</td> <td> 0.000</td> <td>    1.123</td> <td>    2.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Topic4</th>    <td>    1.5482</td> <td>    0.263</td> <td>    5.890</td> <td> 0.000</td> <td>    1.033</td> <td>    2.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Topic5</th>    <td>    0.8582</td> <td>    0.263</td> <td>    3.260</td> <td> 0.001</td> <td>    0.342</td> <td>    1.374</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Topic6</th>    <td>    1.5360</td> <td>    0.263</td> <td>    5.839</td> <td> 0.000</td> <td>    1.020</td> <td>    2.052</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>123499.177</td> <th>  Durbin-Watson:     </th>  <td>   1.756</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>1075667.430</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td>-2.758</td>   <th>  Prob(JB):          </th>  <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>        <td>12.571</td>   <th>  Cond. No.          </th>  <td>    542.</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  Score   R-squared:                       0.060\n",
       "Model:                            OLS   Adj. R-squared:                  0.060\n",
       "Method:                 Least Squares   F-statistic:                     2265.\n",
       "Date:                Mon, 23 May 2022   Prob (F-statistic):               0.00\n",
       "Time:                        00:29:10   Log-Likelihood:            -2.0523e+05\n",
       "No. Observations:              211535   AIC:                         4.105e+05\n",
       "Df Residuals:                  211528   BIC:                         4.106e+05\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      3.3455      0.263     12.744      0.000       2.831       3.860\n",
       "Topic1         1.0739      0.263      4.081      0.000       0.558       1.590\n",
       "Topic2         1.5554      0.263      5.917      0.000       1.040       2.071\n",
       "Topic3         1.6377      0.263      6.232      0.000       1.123       2.153\n",
       "Topic4         1.5482      0.263      5.890      0.000       1.033       2.063\n",
       "Topic5         0.8582      0.263      3.260      0.001       0.342       1.374\n",
       "Topic6         1.5360      0.263      5.839      0.000       1.020       2.052\n",
       "==============================================================================\n",
       "Omnibus:                   123499.177   Durbin-Watson:                   1.756\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1075667.430\n",
       "Skew:                          -2.758   Prob(JB):                         0.00\n",
       "Kurtosis:                      12.571   Cond. No.                         542.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "model = ols(\"Score ~ Topic1 + Topic2 + Topic3 + Topic4 + Topic5 + Topic6\", data = topic_porb).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 ~ 5 점으로 Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Topic1    2.107237\n",
       "Topic2    4.577747\n",
       "Topic3    5.000000\n",
       "Topic4    4.541009\n",
       "Topic5    1.000000\n",
       "Topic6    4.478112\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 + (model.params[1:] - min(model.params[1:])) / (max(model.params[1:]) - min(model.params[1:])) * 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 토빗 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "import scipy.stats\n",
    "from scipy.special import log_ndtr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "def split_left_right_censored(x, y, cens):\n",
    "    counts = cens.value_counts()\n",
    "    if -1 not in counts and 1 not in counts:\n",
    "        warnings.warn(\"No censored observations; use regression methods for uncensored data\")\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "    for value in [-1, 0, 1]:\n",
    "        if value in counts:\n",
    "            split = cens == value\n",
    "            y_split = np.squeeze(y[split].values)\n",
    "            x_split = x[split].values\n",
    "\n",
    "        else:\n",
    "            y_split, x_split = None, None\n",
    "        xs.append(x_split)\n",
    "        ys.append(y_split)\n",
    "    return xs, ys\n",
    "\n",
    "\n",
    "def tobit_neg_log_likelihood(xs, ys, params):\n",
    "    x_left, x_mid, x_right = xs\n",
    "    y_left, y_mid, y_right = ys\n",
    "\n",
    "    b = params[:-1]\n",
    "    # s = math.exp(params[-1])\n",
    "    s = params[-1]\n",
    "\n",
    "    to_cat = []\n",
    "\n",
    "    cens = False\n",
    "    if y_left is not None:\n",
    "        cens = True\n",
    "        left = (y_left - np.dot(x_left, b))\n",
    "        to_cat.append(left)\n",
    "    if y_right is not None:\n",
    "        cens = True\n",
    "        right = (np.dot(x_right, b) - y_right)\n",
    "        to_cat.append(right)\n",
    "    if cens:\n",
    "        concat_stats = np.concatenate(to_cat, axis=0) / s\n",
    "        log_cum_norm = scipy.stats.norm.logcdf(concat_stats)  # log_ndtr(concat_stats)\n",
    "        cens_sum = log_cum_norm.sum()\n",
    "    else:\n",
    "        cens_sum = 0\n",
    "\n",
    "    if y_mid is not None:\n",
    "        mid_stats = (y_mid - np.dot(x_mid, b)) / s\n",
    "        mid = scipy.stats.norm.logpdf(mid_stats) - math.log(max(np.finfo('float').resolution, s))\n",
    "        mid_sum = mid.sum()\n",
    "    else:\n",
    "        mid_sum = 0\n",
    "\n",
    "    loglik = cens_sum + mid_sum\n",
    "\n",
    "    return - loglik\n",
    "\n",
    "\n",
    "def tobit_neg_log_likelihood_der(xs, ys, params):\n",
    "    x_left, x_mid, x_right = xs\n",
    "    y_left, y_mid, y_right = ys\n",
    "\n",
    "    b = params[:-1]\n",
    "    # s = math.exp(params[-1]) # in censReg, not using chain rule as below; they optimize in terms of log(s)\n",
    "    s = params[-1]\n",
    "\n",
    "    beta_jac = np.zeros(len(b))\n",
    "    sigma_jac = 0\n",
    "\n",
    "    if y_left is not None:\n",
    "        left_stats = (y_left - np.dot(x_left, b)) / s\n",
    "        l_pdf = scipy.stats.norm.logpdf(left_stats)\n",
    "        l_cdf = log_ndtr(left_stats)\n",
    "        left_frac = np.exp(l_pdf - l_cdf)\n",
    "        beta_left = np.dot(left_frac, x_left / s)\n",
    "        beta_jac -= beta_left\n",
    "\n",
    "        left_sigma = np.dot(left_frac, left_stats)\n",
    "        sigma_jac -= left_sigma\n",
    "\n",
    "    if y_right is not None:\n",
    "        right_stats = (np.dot(x_right, b) - y_right) / s\n",
    "        r_pdf = scipy.stats.norm.logpdf(right_stats)\n",
    "        r_cdf = log_ndtr(right_stats)\n",
    "        right_frac = np.exp(r_pdf - r_cdf)\n",
    "        beta_right = np.dot(right_frac, x_right / s)\n",
    "        beta_jac += beta_right\n",
    "\n",
    "        right_sigma = np.dot(right_frac, right_stats)\n",
    "        sigma_jac -= right_sigma\n",
    "\n",
    "    if y_mid is not None:\n",
    "        mid_stats = (y_mid - np.dot(x_mid, b)) / s\n",
    "        beta_mid = np.dot(mid_stats, x_mid / s)\n",
    "        beta_jac += beta_mid\n",
    "\n",
    "        mid_sigma = (np.square(mid_stats) - 1).sum()\n",
    "        sigma_jac += mid_sigma\n",
    "\n",
    "    combo_jac = np.append(beta_jac, sigma_jac / s)  # by chain rule, since the expression above is dloglik/dlogsigma\n",
    "\n",
    "    return -combo_jac\n",
    "\n",
    "\n",
    "class TobitModel:\n",
    "    def __init__(self, fit_intercept=True):\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.ols_coef_ = None\n",
    "        self.ols_intercept = None\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        self.sigma_ = None\n",
    "\n",
    "    def fit(self, x, y, cens, verbose=False):\n",
    "        \"\"\"\n",
    "        Fit a maximum-likelihood Tobit regression\n",
    "        :param x: Pandas DataFrame (n_samples, n_features): Data\n",
    "        :param y: Pandas Series (n_samples,): Target\n",
    "        :param cens: Pandas Series (n_samples,): -1 indicates left-censored samples, 0 for uncensored, 1 for right-censored\n",
    "        :param verbose: boolean, show info from minimization\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        x_copy = x.copy()\n",
    "        if self.fit_intercept:\n",
    "            x_copy.insert(0, 'intercept', 1.0)\n",
    "        else:\n",
    "            x_copy.scale(with_mean=True, with_std=False, copy=False)\n",
    "        init_reg = LinearRegression(fit_intercept=False).fit(x_copy, y)\n",
    "        b0 = init_reg.coef_\n",
    "        y_pred = init_reg.predict(x_copy)\n",
    "        resid = y - y_pred\n",
    "        resid_var = np.var(resid)\n",
    "        s0 = np.sqrt(resid_var)\n",
    "        params0 = np.append(b0, s0)\n",
    "        xs, ys = split_left_right_censored(x_copy, y, cens)\n",
    "\n",
    "        result = minimize(lambda params: tobit_neg_log_likelihood(xs, ys, params), params0, method='BFGS',\n",
    "                          jac=lambda params: tobit_neg_log_likelihood_der(xs, ys, params), options={'disp': verbose})\n",
    "        if verbose:\n",
    "            print(result)\n",
    "        self.ols_coef_ = b0[1:]\n",
    "        self.ols_intercept = b0[0]\n",
    "        if self.fit_intercept:\n",
    "            self.intercept_ = result.x[1]\n",
    "            self.coef_ = result.x[1:-1]\n",
    "        else:\n",
    "            self.coef_ = result.x[:-1]\n",
    "            self.intercept_ = 0\n",
    "        self.sigma_ = result.x[-1]\n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.intercept_ + np.dot(x, self.coef_)\n",
    "\n",
    "    def score(self, x, y, scoring_function=mean_absolute_error):\n",
    "        y_pred = np.dot(x, self.coef_)\n",
    "        return scoring_function(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Topic1</td>\n",
       "      <td>1.077015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Topic2</td>\n",
       "      <td>1.556538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Topic3</td>\n",
       "      <td>1.638573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Topic4</td>\n",
       "      <td>1.549865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Topic5</td>\n",
       "      <td>0.867329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Topic6</td>\n",
       "      <td>1.537196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic      Coef\n",
       "0  Topic1  1.077015\n",
       "1  Topic2  1.556538\n",
       "2  Topic3  1.638573\n",
       "3  Topic4  1.549865\n",
       "4  Topic5  0.867329\n",
       "5  Topic6  1.537196"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tobit = TobitModel().fit(topic_porb.iloc[:, :-1], topic_porb['Score'], topic_porb['Score'])\n",
    "result = pd.DataFrame({\"Topic\" : ['Topic1', 'Topic2', 'Topic3', 'Topic4', 'Topic5', 'Topic6'], 'Coef': tobit.coef_})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 ~ 5 점으로 Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Topic1</td>\n",
       "      <td>2.087523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Topic2</td>\n",
       "      <td>4.574531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Topic3</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Topic4</td>\n",
       "      <td>4.539923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Topic5</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Topic6</td>\n",
       "      <td>4.474214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic      Coef\n",
       "0  Topic1  2.087523\n",
       "1  Topic2  4.574531\n",
       "2  Topic3  5.000000\n",
       "3  Topic4  4.539923\n",
       "4  Topic5  1.000000\n",
       "5  Topic6  4.474214"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef = 1 + (tobit.coef_ - min(tobit.coef_)) / (max(tobit.coef_) - min(tobit.coef_)) * 4\n",
    "result = pd.DataFrame({\"Topic\" : ['Topic1', 'Topic2', 'Topic3', 'Topic4', 'Topic5', 'Topic6'], 'Coef': coef})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
